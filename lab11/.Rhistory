library(ggplot2)
blad = function(E1, E2)
{
sum(E1 != E2) / length(E1)
}
generujZbior = function(srednia1, srednia2, n)
{
dane1 = mvrnorm(n, srednia1, Sigma = diag(c(1, 1)))
ramka1 = data.frame(x = dane1[, 1], y = dane1[, 2], etykieta = rep(1, nrow(dane1)))
dane2 = mvrnorm(n, srednia2, Sigma = diag(c(1, 1)))
ramka2 = data.frame(x = dane2[, 1], y = dane2[, 2], etykieta = rep(2, nrow(dane2)))
ramka = rbind(ramka1, ramka2)
}
rysujZbior = function(zbior, fx)
{
plot(
NULL,
fitted(fx),
asp = 1,
xlim = c(-3, 3),
ylim = c(-3, 3),
xlab = "x",
ylab = "y",
main = deparse(substitute(zbior))
)
points(zbior, col = zbior$etykieta)
}
obliczBlad = function(zbior, przesuniece, kat)
{
a = tan(kat*pi/180) # y=ax+b
b = przesuniecie
etyk = rep(2, nrow(zbior))
etyk[zbior$y < a * zbior$x + b] = 1
blad(etyk, zbior$etykieta)
}
obliczBlad2 = function(zbior, fx)
{
etyk = rep(2, nrow(zbior))
etyk[zbior$y < fx] = 1
blad(etyk, zbior$etykieta)
}
set.seed(1)
zbior = generujZbior(c(-1, -1), c(1, 1), 100)
a = 1
b = 1
c = 1
fx = a * zbior$x^2 + b * zbior$x + c
obliczBlad2(zbior, fx)
rysujZbior(zbior, fx)
#przesuniecie = 0
#kat = 135
#obliczBlad(zbior, przesuniecie, kat)
# 1. Supervised (z nadzorem), Unsupervised (bez nadzoru), Reinforcenment (ze wzmocnieniem)
# 2. tak
# 3. tak
# 4. tak
# 5. n-krotnie losujemy pojedyczną obserwacje ze zwraceniem z n-elementowej próby uczącej
###
# 6. Uczenie się pod nadzorem lub uczenie się z przykładów jest procesem budowy, na bazie dostępnych
#    danych wejściowych Xi oraz wejściowych Yi, i = 1, 2 ..., n, reguły klasyfikacyjnen zwanej inaczej klasyfikatorem,
#    służącej do predykcji etykiety Y grupy, do której należy obserwacja X
# 7. Chcemy na podstawie wektora cech X znaleźć odpowiednią etykiete Y. Naszym celem jest znalezienie takiego
#    klasyfikatora d, który daje dokładną predykcję. Miarą jakości takiego klasyfikatora jest jego rzeczywisty poziom błędy
#         e(d) = P(d(X) != Y)
# 8. Klasyfikator bayesowski jest OPTYMALNY, tj. jeżeli d jest jakimkolwiek innym klasyfikatorem, to e(dB) <= e(d)
#    gdzue e(d) jest rzeczywistym poziomem błędy klasyfikatora d.
#
#    Niestety, klasyfikator bayesowski zależy od rozkładu prawdopodobieństwa pary (X, Y). Najczęściec rozkład ten nie jest znany
#    i stąd również nie jest znany klasyfikator bayesowski dB.
# 9. Błąd ponownego podstawienia polega na użyciu próby uczącej jakko próby testowej. Należy podzielić probę na 2 podzbiory: próbę
#    uczącą oraz próbę testową, aby błąd ponownego podstawienia nie pojawiał się.
# 10 Overfitting występuje, kiedy dostosowujemy model dokładnie do danych treningowych. W takiej sytuacji model nie będzie w stanie
#    prawidłowo przewidzieć etykiet dla danych testowych. Przeuczenie dostosowuje się dokładnie do danych treningowych, kiedy
#    uczony jest zbyt długo na danym datasecie lub kiedy model jest zbyt złożony.
###
# 11.
library(MASS)
library(ggplot2)
blad = function(E1, E2)
{
sum(E1 != E2) / length(E1)
}
generujZbior = function(srednia1, srednia2, n)
{
dane1 = mvrnorm(n, srednia1, Sigma = diag(c(1, 1)))
ramka1 = data.frame(x = dane1[, 1], y = dane1[, 2], etykieta = rep(1, nrow(dane1)))
dane2 = mvrnorm(n, srednia2, Sigma = diag(c(1, 1)))
ramka2 = data.frame(x = dane2[, 1], y = dane2[, 2], etykieta = rep(2, nrow(dane2)))
ramka = rbind(ramka1, ramka2)
}
rysujZbior = function(zbior, fx)
{
plot(
NULL,
asp = 1,
xlim = c(-3, 3),
ylim = c(-3, 3),
xlab = "x",
ylab = "y",
main = deparse(substitute(zbior))
)
points(zbior, col = zbior$etykieta)
}
obliczBlad = function(zbior, przesuniece, kat)
{
a = tan(kat*pi/180) # y=ax+b
b = przesuniecie
etyk = rep(2, nrow(zbior))
etyk[zbior$y < a * zbior$x + b] = 1
blad(etyk, zbior$etykieta)
}
obliczBlad2 = function(zbior, fx)
{
etyk = rep(2, nrow(zbior))
etyk[zbior$y < fx] = 1
blad(etyk, zbior$etykieta)
}
set.seed(1)
zbior = generujZbior(c(-1, -1), c(1, 1), 100)
a = 1
b = 1
c = 1
fx = a * zbior$x^2 + b * zbior$x + c
obliczBlad2(zbior, fx)
rysujZbior(zbior, fx)
#przesuniecie = 0
#kat = 135
#obliczBlad(zbior, przesuniecie, kat)
# 1. Supervised (z nadzorem), Unsupervised (bez nadzoru), Reinforcenment (ze wzmocnieniem)
# 2. tak
# 3. tak
# 4. tak
# 5. n-krotnie losujemy pojedyczną obserwacje ze zwraceniem z n-elementowej próby uczącej
###
# 6. Uczenie się pod nadzorem lub uczenie się z przykładów jest procesem budowy, na bazie dostępnych
#    danych wejściowych Xi oraz wejściowych Yi, i = 1, 2 ..., n, reguły klasyfikacyjnen zwanej inaczej klasyfikatorem,
#    służącej do predykcji etykiety Y grupy, do której należy obserwacja X
# 7. Chcemy na podstawie wektora cech X znaleźć odpowiednią etykiete Y. Naszym celem jest znalezienie takiego
#    klasyfikatora d, który daje dokładną predykcję. Miarą jakości takiego klasyfikatora jest jego rzeczywisty poziom błędy
#         e(d) = P(d(X) != Y)
# 8. Klasyfikator bayesowski jest OPTYMALNY, tj. jeżeli d jest jakimkolwiek innym klasyfikatorem, to e(dB) <= e(d)
#    gdzue e(d) jest rzeczywistym poziomem błędy klasyfikatora d.
#
#    Niestety, klasyfikator bayesowski zależy od rozkładu prawdopodobieństwa pary (X, Y). Najczęściec rozkład ten nie jest znany
#    i stąd również nie jest znany klasyfikator bayesowski dB.
# 9. Błąd ponownego podstawienia polega na użyciu próby uczącej jakko próby testowej. Należy podzielić probę na 2 podzbiory: próbę
#    uczącą oraz próbę testową, aby błąd ponownego podstawienia nie pojawiał się.
# 10 Overfitting występuje, kiedy dostosowujemy model dokładnie do danych treningowych. W takiej sytuacji model nie będzie w stanie
#    prawidłowo przewidzieć etykiet dla danych testowych. Przeuczenie dostosowuje się dokładnie do danych treningowych, kiedy
#    uczony jest zbyt długo na danym datasecie lub kiedy model jest zbyt złożony.
###
# 11.
library(MASS)
library(ggplot2)
blad = function(E1, E2)
{
sum(E1 != E2) / length(E1)
}
generujZbior = function(srednia1, srednia2, n)
{
dane1 = mvrnorm(n, srednia1, Sigma = diag(c(1, 1)))
ramka1 = data.frame(x = dane1[, 1], y = dane1[, 2], etykieta = rep(1, nrow(dane1)))
dane2 = mvrnorm(n, srednia2, Sigma = diag(c(1, 1)))
ramka2 = data.frame(x = dane2[, 1], y = dane2[, 2], etykieta = rep(2, nrow(dane2)))
ramka = rbind(ramka1, ramka2)
}
rysujZbior = function(zbior, fx)
{
plot(
NULL,
asp = 1,
xlim = c(-3, 3),
ylim = c(-3, 3),
xlab = "x",
ylab = "y",
main = deparse(substitute(zbior))
)
lines(fx, col="darkgreen", lwd=3)
points(zbior, col = zbior$etykieta)
}
obliczBlad = function(zbior, przesuniece, kat)
{
a = tan(kat*pi/180) # y=ax+b
b = przesuniecie
etyk = rep(2, nrow(zbior))
etyk[zbior$y < a * zbior$x + b] = 1
blad(etyk, zbior$etykieta)
}
obliczBlad2 = function(zbior, fx)
{
etyk = rep(2, nrow(zbior))
etyk[zbior$y < fx] = 1
blad(etyk, zbior$etykieta)
}
set.seed(1)
zbior = generujZbior(c(-1, -1), c(1, 1), 100)
a = 1
b = 1
c = 1
fx = a * zbior$x^2 + b * zbior$x + c
obliczBlad2(zbior, fx)
rysujZbior(zbior, fx)
#przesuniecie = 0
#kat = 135
#obliczBlad(zbior, przesuniecie, kat)
# 1. Supervised (z nadzorem), Unsupervised (bez nadzoru), Reinforcenment (ze wzmocnieniem)
# 2. tak
# 3. tak
# 4. tak
# 5. n-krotnie losujemy pojedyczną obserwacje ze zwraceniem z n-elementowej próby uczącej
###
# 6. Uczenie się pod nadzorem lub uczenie się z przykładów jest procesem budowy, na bazie dostępnych
#    danych wejściowych Xi oraz wejściowych Yi, i = 1, 2 ..., n, reguły klasyfikacyjnen zwanej inaczej klasyfikatorem,
#    służącej do predykcji etykiety Y grupy, do której należy obserwacja X
# 7. Chcemy na podstawie wektora cech X znaleźć odpowiednią etykiete Y. Naszym celem jest znalezienie takiego
#    klasyfikatora d, który daje dokładną predykcję. Miarą jakości takiego klasyfikatora jest jego rzeczywisty poziom błędy
#         e(d) = P(d(X) != Y)
# 8. Klasyfikator bayesowski jest OPTYMALNY, tj. jeżeli d jest jakimkolwiek innym klasyfikatorem, to e(dB) <= e(d)
#    gdzue e(d) jest rzeczywistym poziomem błędy klasyfikatora d.
#
#    Niestety, klasyfikator bayesowski zależy od rozkładu prawdopodobieństwa pary (X, Y). Najczęściec rozkład ten nie jest znany
#    i stąd również nie jest znany klasyfikator bayesowski dB.
# 9. Błąd ponownego podstawienia polega na użyciu próby uczącej jakko próby testowej. Należy podzielić probę na 2 podzbiory: próbę
#    uczącą oraz próbę testową, aby błąd ponownego podstawienia nie pojawiał się.
# 10 Overfitting występuje, kiedy dostosowujemy model dokładnie do danych treningowych. W takiej sytuacji model nie będzie w stanie
#    prawidłowo przewidzieć etykiet dla danych testowych. Przeuczenie dostosowuje się dokładnie do danych treningowych, kiedy
#    uczony jest zbyt długo na danym datasecie lub kiedy model jest zbyt złożony.
###
# 11.
library(MASS)
library(ggplot2)
blad = function(E1, E2)
{
sum(E1 != E2) / length(E1)
}
generujZbior = function(srednia1, srednia2, n)
{
dane1 = mvrnorm(n, srednia1, Sigma = diag(c(1, 1)))
ramka1 = data.frame(x = dane1[, 1], y = dane1[, 2], etykieta = rep(1, nrow(dane1)))
dane2 = mvrnorm(n, srednia2, Sigma = diag(c(1, 1)))
ramka2 = data.frame(x = dane2[, 1], y = dane2[, 2], etykieta = rep(2, nrow(dane2)))
ramka = rbind(ramka1, ramka2)
}
rysujZbior = function(zbior, fx)
{
plot(
NULL,
asp = 1,
xlim = c(-3, 3),
ylim = c(-3, 3),
xlab = "x",
ylab = "y",
main = deparse(substitute(zbior))
)
lines(-3:3, fx, col="darkgreen", lwd=3)
points(zbior, col = zbior$etykieta)
}
obliczBlad = function(zbior, przesuniece, kat)
{
a = tan(kat*pi/180) # y=ax+b
b = przesuniecie
etyk = rep(2, nrow(zbior))
etyk[zbior$y < a * zbior$x + b] = 1
blad(etyk, zbior$etykieta)
}
obliczBlad2 = function(zbior, fx)
{
etyk = rep(2, nrow(zbior))
etyk[zbior$y < fx] = 1
blad(etyk, zbior$etykieta)
}
set.seed(1)
zbior = generujZbior(c(-1, -1), c(1, 1), 100)
a = 1
b = 1
c = 1
fx = a * zbior$x^2 + b * zbior$x + c
obliczBlad2(zbior, fx)
rysujZbior(zbior, fx)
#przesuniecie = 0
#kat = 135
#obliczBlad(zbior, przesuniecie, kat)
# 1. Supervised (z nadzorem), Unsupervised (bez nadzoru), Reinforcenment (ze wzmocnieniem)
# 2. tak
# 3. tak
# 4. tak
# 5. n-krotnie losujemy pojedyczną obserwacje ze zwraceniem z n-elementowej próby uczącej
###
# 6. Uczenie się pod nadzorem lub uczenie się z przykładów jest procesem budowy, na bazie dostępnych
#    danych wejściowych Xi oraz wejściowych Yi, i = 1, 2 ..., n, reguły klasyfikacyjnen zwanej inaczej klasyfikatorem,
#    służącej do predykcji etykiety Y grupy, do której należy obserwacja X
# 7. Chcemy na podstawie wektora cech X znaleźć odpowiednią etykiete Y. Naszym celem jest znalezienie takiego
#    klasyfikatora d, który daje dokładną predykcję. Miarą jakości takiego klasyfikatora jest jego rzeczywisty poziom błędy
#         e(d) = P(d(X) != Y)
# 8. Klasyfikator bayesowski jest OPTYMALNY, tj. jeżeli d jest jakimkolwiek innym klasyfikatorem, to e(dB) <= e(d)
#    gdzue e(d) jest rzeczywistym poziomem błędy klasyfikatora d.
#
#    Niestety, klasyfikator bayesowski zależy od rozkładu prawdopodobieństwa pary (X, Y). Najczęściec rozkład ten nie jest znany
#    i stąd również nie jest znany klasyfikator bayesowski dB.
# 9. Błąd ponownego podstawienia polega na użyciu próby uczącej jakko próby testowej. Należy podzielić probę na 2 podzbiory: próbę
#    uczącą oraz próbę testową, aby błąd ponownego podstawienia nie pojawiał się.
# 10 Overfitting występuje, kiedy dostosowujemy model dokładnie do danych treningowych. W takiej sytuacji model nie będzie w stanie
#    prawidłowo przewidzieć etykiet dla danych testowych. Przeuczenie dostosowuje się dokładnie do danych treningowych, kiedy
#    uczony jest zbyt długo na danym datasecie lub kiedy model jest zbyt złożony.
###
# 11.
library(MASS)
library(ggplot2)
blad = function(E1, E2)
{
sum(E1 != E2) / length(E1)
}
generujZbior = function(srednia1, srednia2, n)
{
dane1 = mvrnorm(n, srednia1, Sigma = diag(c(1, 1)))
ramka1 = data.frame(x = dane1[, 1], y = dane1[, 2], etykieta = rep(1, nrow(dane1)))
dane2 = mvrnorm(n, srednia2, Sigma = diag(c(1, 1)))
ramka2 = data.frame(x = dane2[, 1], y = dane2[, 2], etykieta = rep(2, nrow(dane2)))
ramka = rbind(ramka1, ramka2)
}
rysujZbior = function(zbior, fx)
{
plot(
NULL,
asp = 1,
xlim = c(-3, 3),
ylim = c(-3, 3),
xlab = "x",
ylab = "y",
main = deparse(substitute(zbior))
)
lines(seq(-10, 10, 0.1), fx, col="darkgreen", lwd=3)
points(zbior, col = zbior$etykieta)
}
obliczBlad = function(zbior, przesuniece, kat)
{
a = tan(kat*pi/180) # y=ax+b
b = przesuniecie
etyk = rep(2, nrow(zbior))
etyk[zbior$y < a * zbior$x + b] = 1
blad(etyk, zbior$etykieta)
}
obliczBlad2 = function(zbior, fx)
{
etyk = rep(2, nrow(zbior))
etyk[zbior$y < fx] = 1
blad(etyk, zbior$etykieta)
}
set.seed(1)
zbior = generujZbior(c(-1, -1), c(1, 1), 100)
a = 1
b = 1
c = 1
fx = a * zbior$x^2 + b * zbior$x + c
obliczBlad2(zbior, fx)
rysujZbior(zbior, fx)
#przesuniecie = 0
#kat = 135
#obliczBlad(zbior, przesuniecie, kat)
# 1. Supervised (z nadzorem), Unsupervised (bez nadzoru), Reinforcenment (ze wzmocnieniem)
# 2. tak
# 3. tak
# 4. tak
# 5. n-krotnie losujemy pojedyczną obserwacje ze zwraceniem z n-elementowej próby uczącej
###
# 6. Uczenie się pod nadzorem lub uczenie się z przykładów jest procesem budowy, na bazie dostępnych
#    danych wejściowych Xi oraz wejściowych Yi, i = 1, 2 ..., n, reguły klasyfikacyjnen zwanej inaczej klasyfikatorem,
#    służącej do predykcji etykiety Y grupy, do której należy obserwacja X
# 7. Chcemy na podstawie wektora cech X znaleźć odpowiednią etykiete Y. Naszym celem jest znalezienie takiego
#    klasyfikatora d, który daje dokładną predykcję. Miarą jakości takiego klasyfikatora jest jego rzeczywisty poziom błędy
#         e(d) = P(d(X) != Y)
# 8. Klasyfikator bayesowski jest OPTYMALNY, tj. jeżeli d jest jakimkolwiek innym klasyfikatorem, to e(dB) <= e(d)
#    gdzue e(d) jest rzeczywistym poziomem błędy klasyfikatora d.
#
#    Niestety, klasyfikator bayesowski zależy od rozkładu prawdopodobieństwa pary (X, Y). Najczęściec rozkład ten nie jest znany
#    i stąd również nie jest znany klasyfikator bayesowski dB.
# 9. Błąd ponownego podstawienia polega na użyciu próby uczącej jakko próby testowej. Należy podzielić probę na 2 podzbiory: próbę
#    uczącą oraz próbę testową, aby błąd ponownego podstawienia nie pojawiał się.
# 10 Overfitting występuje, kiedy dostosowujemy model dokładnie do danych treningowych. W takiej sytuacji model nie będzie w stanie
#    prawidłowo przewidzieć etykiet dla danych testowych. Przeuczenie dostosowuje się dokładnie do danych treningowych, kiedy
#    uczony jest zbyt długo na danym datasecie lub kiedy model jest zbyt złożony.
###
# 11.
library(MASS)
library(ggplot2)
blad = function(E1, E2)
{
sum(E1 != E2) / length(E1)
}
generujZbior = function(srednia1, srednia2, n)
{
dane1 = mvrnorm(n, srednia1, Sigma = diag(c(1, 1)))
ramka1 = data.frame(x = dane1[, 1], y = dane1[, 2], etykieta = rep(1, nrow(dane1)))
dane2 = mvrnorm(n, srednia2, Sigma = diag(c(1, 1)))
ramka2 = data.frame(x = dane2[, 1], y = dane2[, 2], etykieta = rep(2, nrow(dane2)))
ramka = rbind(ramka1, ramka2)
}
rysujZbior = function(zbior, fx)
{
plot(
NULL,
asp = 1,
xlim = c(-3, 3),
ylim = c(-3, 3),
xlab = "x",
ylab = "y",
main = deparse(substitute(zbior))
)
points(zbior, col = zbior$etykieta)
}
obliczBlad = function(zbior, przesuniece, kat)
{
a = tan(kat*pi/180) # y=ax+b
b = przesuniecie
etyk = rep(2, nrow(zbior))
etyk[zbior$y < a * zbior$x + b] = 1
blad(etyk, zbior$etykieta)
}
obliczBlad2 = function(zbior, fx)
{
etyk = rep(2, nrow(zbior))
etyk[zbior$y < fx] = 1
blad(etyk, zbior$etykieta)
}
set.seed(1)
zbior = generujZbior(c(-1, -1), c(1, 1), 100)
a = 1
b = 1
c = 1
fx = a * zbior$x^2 + b * zbior$x + c
obliczBlad2(zbior, fx)
rysujZbior(zbior, fx)
#przesuniecie = 0
#kat = 135
#obliczBlad(zbior, przesuniecie, kat)
# 1. Supervised (z nadzorem), Unsupervised (bez nadzoru), Reinforcenment (ze wzmocnieniem)
# 2. tak
# 3. tak
# 4. tak
# 5. n-krotnie losujemy pojedyczną obserwacje ze zwraceniem z n-elementowej próby uczącej
###
# 6. Uczenie się pod nadzorem lub uczenie się z przykładów jest procesem budowy, na bazie dostępnych
#    danych wejściowych Xi oraz wejściowych Yi, i = 1, 2 ..., n, reguły klasyfikacyjnen zwanej inaczej klasyfikatorem,
#    służącej do predykcji etykiety Y grupy, do której należy obserwacja X
# 7. Chcemy na podstawie wektora cech X znaleźć odpowiednią etykiete Y. Naszym celem jest znalezienie takiego
#    klasyfikatora d, który daje dokładną predykcję. Miarą jakości takiego klasyfikatora jest jego rzeczywisty poziom błędy
#         e(d) = P(d(X) != Y)
# 8. Klasyfikator bayesowski jest OPTYMALNY, tj. jeżeli d jest jakimkolwiek innym klasyfikatorem, to e(dB) <= e(d)
#    gdzue e(d) jest rzeczywistym poziomem błędy klasyfikatora d.
#
#    Niestety, klasyfikator bayesowski zależy od rozkładu prawdopodobieństwa pary (X, Y). Najczęściec rozkład ten nie jest znany
#    i stąd również nie jest znany klasyfikator bayesowski dB.
# 9. Błąd ponownego podstawienia polega na użyciu próby uczącej jakko próby testowej. Należy podzielić probę na 2 podzbiory: próbę
#    uczącą oraz próbę testową, aby błąd ponownego podstawienia nie pojawiał się.
# 10 Overfitting występuje, kiedy dostosowujemy model dokładnie do danych treningowych. W takiej sytuacji model nie będzie w stanie
#    prawidłowo przewidzieć etykiet dla danych testowych. Przeuczenie dostosowuje się dokładnie do danych treningowych, kiedy
#    uczony jest zbyt długo na danym datasecie lub kiedy model jest zbyt złożony.
###
# 11.
library(MASS)
library(ggplot2)
blad = function(E1, E2)
{
sum(E1 != E2) / length(E1)
}
generujZbior = function(srednia1, srednia2, n)
{
dane1 = mvrnorm(n, srednia1, Sigma = diag(c(1, 1)))
ramka1 = data.frame(x = dane1[, 1], y = dane1[, 2], etykieta = rep(1, nrow(dane1)))
dane2 = mvrnorm(n, srednia2, Sigma = diag(c(1, 1)))
ramka2 = data.frame(x = dane2[, 1], y = dane2[, 2], etykieta = rep(2, nrow(dane2)))
ramka = rbind(ramka1, ramka2)
}
rysujZbior = function(zbior, fx)
{
plot(
NULL,
asp = 1,
xlim = c(-3, 3),
ylim = c(-3, 3),
xlab = "x",
ylab = "y",
main = deparse(substitute(zbior))
)
points(zbior, col = zbior$etykieta)
}
obliczBlad = function(zbior, przesuniece, kat)
{
a = tan(kat*pi/180) # y=ax+b
b = przesuniecie
etyk = rep(2, nrow(zbior))
etyk[zbior$y < a * zbior$x + b] = 1
blad(etyk, zbior$etykieta)
}
obliczBlad2 = function(zbior, fx)
{
etyk = rep(2, nrow(zbior))
etyk[zbior$y < fx] = 1
blad(etyk, zbior$etykieta)
}
set.seed(1)
zbior = generujZbior(c(-1, -1), c(1, 1), 100)
a = 1
b = 1
c = 1
fx = a * zbior$x^2 + b * zbior$x + c
obliczBlad2(zbior, fx)
rysujZbior(zbior, fx)
abline(fx)
#przesuniecie = 0
#kat = 135
#obliczBlad(zbior, przesuniecie, kat)
